{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Install neccessary </h1>"
      ],
      "metadata": {
        "id": "QysHambtFf4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/mini_training.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06_iVuclE3lL",
        "outputId": "6a1de6f9-3380-45a7-f11a-94d6c3ef46e5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/mini_training.zip\n",
            "   creating: mini_training/\n",
            "  inflating: mini_training/s1_d2_p002_002_data_time_series.npy  \n",
            "  inflating: mini_training/s1_d2_p002_002_data_time_stamps.npy  \n",
            "  inflating: mini_training/s1_d2_p002_002_label_time_series.npy  \n",
            "  inflating: mini_training/s1_d2_p002_002_label_time_stamps.npy  \n",
            "  inflating: mini_training/s1_d2_p002_005_data_time_series.npy  \n",
            "  inflating: mini_training/s1_d2_p002_005_data_time_stamps.npy  \n",
            "  inflating: mini_training/s1_d2_p002_005_label_time_series.npy  \n",
            "  inflating: mini_training/s1_d2_p002_005_label_time_stamps.npy  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install braindecode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "e9xv3ylNtwX8",
        "outputId": "9fbdd5d7-2c32-4ea5-a2af-0856075d90d8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting braindecode\n",
            "  Downloading braindecode-0.8.1-py3-none-any.whl (165 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/165.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m112.6/165.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.2/165.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mne (from braindecode)\n",
            "  Downloading mne-1.7.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from braindecode) (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from braindecode) (2.0.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from braindecode) (1.11.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from braindecode) (3.7.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from braindecode) (3.9.0)\n",
            "Collecting skorch (from braindecode)\n",
            "  Downloading skorch-0.15.0-py3-none-any.whl (239 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.3/239.3 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from braindecode) (2.2.1+cu121)\n",
            "Collecting einops (from braindecode)\n",
            "  Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from braindecode) (1.4.2)\n",
            "Collecting torchinfo (from braindecode)\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Collecting docstring-inheritance (from braindecode)\n",
            "  Downloading docstring_inheritance-2.2.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->braindecode) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->braindecode) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->braindecode) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->braindecode) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->braindecode) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->braindecode) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->braindecode) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->braindecode) (2.8.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from mne->braindecode) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mne->braindecode) (3.1.4)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.10/dist-packages (from mne->braindecode) (0.4)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.10/dist-packages (from mne->braindecode) (1.8.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mne->braindecode) (4.66.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->braindecode) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->braindecode) (2024.1)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from skorch->braindecode) (1.2.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from skorch->braindecode) (0.9.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->braindecode) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->braindecode) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->braindecode) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->braindecode) (3.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->braindecode) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->braindecode)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->braindecode)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->braindecode)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->braindecode)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->braindecode)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->braindecode)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->braindecode)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->braindecode)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->braindecode)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch->braindecode)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->braindecode)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->braindecode) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->braindecode)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne->braindecode) (4.2.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.5->mne->braindecode) (2.31.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->braindecode) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.0->skorch->braindecode) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mne->braindecode) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->braindecode) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne->braindecode) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne->braindecode) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne->braindecode) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.5->mne->braindecode) (2024.2.2)\n",
            "Installing collected packages: torchinfo, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, einops, docstring-inheritance, nvidia-cusparse-cu12, nvidia-cudnn-cu12, skorch, nvidia-cusolver-cu12, mne, braindecode\n",
            "Successfully installed braindecode-0.8.1 docstring-inheritance-2.2.0 einops-0.8.0 mne-1.7.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 skorch-0.15.0 torchinfo-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPrENuTptQgh",
        "outputId": "37651f48-e8c6-45fc-f052-8a07b4a722e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All the Braindecode models:\n",
            "['ATCNet', 'Deep4Net', 'DeepSleepNet', 'EEGConformer', 'EEGITNet', 'EEGInception', 'EEGInceptionERP', 'EEGInceptionMI', 'EEGNetv1', 'EEGNetv4', 'EEGResNet', 'HybridNet', 'ShallowFBCSPNet', 'SleepStagerBlanco2020', 'SleepStagerChambon2018', 'SleepStagerEldele2021', 'TCN', 'TIDNet', 'USleep']\n"
          ]
        }
      ],
      "source": [
        "from braindecode.models.util import models_dict\n",
        "\n",
        "print(f'All the Braindecode models:\\n{list(models_dict.keys())}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from braindecode.models import ShallowFBCSPNet\n"
      ],
      "metadata": {
        "id": "2iOoBd52ufDb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ShallowFBCSPNet.__doc__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuyVh3wauhui",
        "outputId": "d7cd8fb7-9a9e-41c7-ad80-dbe9e5ae219c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shallow ConvNet model from Schirrmeister et al 2017.\n",
            "\n",
            "Model described in [Schirrmeister2017]_.\n",
            "\n",
            "Parameters\n",
            "----------\n",
            "n_chans : int\n",
            "    Number of EEG channels.\n",
            "n_outputs : int\n",
            "    Number of outputs of the model. This is the number of classes\n",
            "    in the case of classification.\n",
            "n_times : int\n",
            "    Number of time samples of the input window.\n",
            "n_filters_time: int\n",
            "    Number of temporal filters.\n",
            "filter_time_length: int\n",
            "    Length of the temporal filter.\n",
            "n_filters_spat: int\n",
            "    Number of spatial filters.\n",
            "pool_time_length: int\n",
            "    Length of temporal pooling filter.\n",
            "pool_time_stride: int\n",
            "    Length of stride between temporal pooling filters.\n",
            "final_conv_length: int | str\n",
            "    Length of the final convolution layer.\n",
            "    If set to \"auto\", length of the input signal must be specified.\n",
            "conv_nonlin: callable\n",
            "    Non-linear function to be used after convolution layers.\n",
            "pool_mode: str\n",
            "    Method to use on pooling layers. \"max\" or \"mean\".\n",
            "pool_nonlin: callable\n",
            "    Non-linear function to be used after pooling layers.\n",
            "split_first_layer: bool\n",
            "    Split first layer into temporal and spatial layers (True) or just use temporal (False).\n",
            "    There would be no non-linearity between the split layers.\n",
            "batch_norm: bool\n",
            "    Whether to use batch normalisation.\n",
            "batch_norm_alpha: float\n",
            "    Momentum for BatchNorm2d.\n",
            "drop_prob: float\n",
            "    Dropout probability.\n",
            "chs_info : list of dict\n",
            "    Information about each individual EEG channel. This should be filled with\n",
            "    ``info[\"chs\"]``. Refer to :class:`mne.Info` for more details.\n",
            "input_window_seconds : float\n",
            "    Length of the input window in seconds.\n",
            "sfreq : float\n",
            "    Sampling frequency of the EEG recordings.\n",
            "in_chans : int\n",
            "    Alias for `n_chans`.\n",
            "n_classes: int\n",
            "    Alias for `n_outputs`.\n",
            "input_window_samples: int | None\n",
            "    Alias for `n_times`.\n",
            "add_log_softmax: bool\n",
            "    Whether to use log-softmax non-linearity as the output function.\n",
            "    LogSoftmax final layer will be removed in the future.\n",
            "    Please adjust your loss function accordingly (e.g. CrossEntropyLoss)!\n",
            "    Check the documentation of the torch.nn loss functions:\n",
            "    https://pytorch.org/docs/stable/nn.html#loss-functions.\n",
            "\n",
            "Raises\n",
            "------\n",
            "ValueError: If some input signal-related parameters are not specified\n",
            "            and can not be inferred.\n",
            "\n",
            "FutureWarning: If add_log_softmax is True, since LogSoftmax final layer\n",
            "               will be removed in the future.\n",
            "\n",
            "Notes\n",
            "-----\n",
            "If some input signal-related parameters are not specified,\n",
            "there will be an attempt to infer them from the other parameters.\n",
            "\n",
            "References\n",
            "----------\n",
            ".. [Schirrmeister2017] Schirrmeister, R. T., Springenberg, J. T., Fiederer,\n",
            "   L. D. J., Glasstetter, M., Eggensperger, K., Tangermann, M., Hutter, F.\n",
            "   & Ball, T. (2017).\n",
            "   Deep learning with convolutional neural networks for EEG decoding and\n",
            "   visualization.\n",
            "   Human Brain Mapping , Aug. 2017.\n",
            "   Online: http://dx.doi.org/10.1002/hbm.23730\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = ShallowFBCSPNet(\n",
        "    n_chans=32,\n",
        "    n_times=1000,\n",
        "    n_outputs=2,\n",
        "    final_conv_length='auto',\n",
        ")\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wn-hFDRRuhrq",
        "outputId": "13a89343-bad1-4715-ff73-5d2764517cb3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================================================================================================\n",
            "Layer (type (var_name):depth-idx)        Input Shape               Output Shape              Param #                   Kernel Shape\n",
            "============================================================================================================================================\n",
            "ShallowFBCSPNet (ShallowFBCSPNet)        [1, 32, 1000]             [1, 2]                    --                        --\n",
            "├─Ensure4d (ensuredims): 1-1             [1, 32, 1000]             [1, 32, 1000, 1]          --                        --\n",
            "├─Rearrange (dimshuffle): 1-2            [1, 32, 1000, 1]          [1, 1, 1000, 32]          --                        --\n",
            "├─CombinedConv (conv_time_spat): 1-3     [1, 1, 1000, 32]          [1, 40, 976, 1]           52,240                    --\n",
            "├─BatchNorm2d (bnorm): 1-4               [1, 40, 976, 1]           [1, 40, 976, 1]           80                        --\n",
            "├─Expression (conv_nonlin_exp): 1-5      [1, 40, 976, 1]           [1, 40, 976, 1]           --                        --\n",
            "├─AvgPool2d (pool): 1-6                  [1, 40, 976, 1]           [1, 40, 61, 1]            --                        [75, 1]\n",
            "├─Expression (pool_nonlin_exp): 1-7      [1, 40, 61, 1]            [1, 40, 61, 1]            --                        --\n",
            "├─Dropout (drop): 1-8                    [1, 40, 61, 1]            [1, 40, 61, 1]            --                        --\n",
            "├─Sequential (final_layer): 1-9          [1, 40, 61, 1]            [1, 2]                    --                        --\n",
            "│    └─Conv2d (conv_classifier): 2-1     [1, 40, 61, 1]            [1, 2, 1, 1]              4,882                     [61, 1]\n",
            "│    └─LogSoftmax (logsoftmax): 2-2      [1, 2, 1, 1]              [1, 2, 1, 1]              --                        --\n",
            "│    └─Expression (squeeze): 2-3         [1, 2, 1, 1]              [1, 2]                    --                        --\n",
            "============================================================================================================================================\n",
            "Total params: 57,202\n",
            "Trainable params: 57,202\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (M): 0.00\n",
            "============================================================================================================================================\n",
            "Input size (MB): 0.13\n",
            "Forward/backward pass size (MB): 0.31\n",
            "Params size (MB): 0.02\n",
            "Estimated Total Size (MB): 0.46\n",
            "============================================================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/braindecode/models/base.py:180: UserWarning: LogSoftmax final layer will be removed! Please adjust your loss function accordingly (e.g. CrossEntropyLoss)!\n",
            "  warnings.warn(\"LogSoftmax final layer will be removed! \" +\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mne\n",
        "import numpy as np\n",
        "\n",
        "info = mne.create_info(ch_names=['C3', 'C4', 'Cz'], sfreq=256., ch_types='eeg')\n",
        "X = np.random.randn(100, 3, 1024)  # 100 epochs, 3 channels, 4 seconds (@256Hz)\n",
        "epochs = mne.EpochsArray(X, info=info)\n",
        "y = np.random.randint(0, 4, size=100)  # 4 classes\n",
        "print(epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2L1cmbXuhpE",
        "outputId": "ad31d6e7-e7e4-4650-ab35-4e805991c2d8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not setting metadata\n",
            "100 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "<EpochsArray |  100 events (all good), 0 – 3.99609 s, baseline off, ~2.4 MB, data loaded,\n",
            " '1': 100>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from skorch.dataset import ValidSplit\n",
        "from braindecode import EEGClassifier\n",
        "\n",
        "net = EEGClassifier(\n",
        "    'ShallowFBCSPNet',\n",
        "    module__final_conv_length='auto',\n",
        "    train_split=ValidSplit(0.2),\n",
        "    # To train a neural network you need validation split, here, we use 20%.\n",
        ")\n"
      ],
      "metadata": {
        "id": "II4Do6Wzuhmt"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net.fit(epochs, y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buqxoZ0IupnN",
        "outputId": "11ff7d8a-af4a-4eb0-a94d-13563a86b182"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch    valid_acc    valid_loss     dur\n",
            "-------  -----------  ------------  ------\n",
            "      1       \u001b[36m0.1500\u001b[0m       \u001b[32m26.6241\u001b[0m  0.0958\n",
            "      2       0.1500       26.6241  0.0348\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/braindecode/models/base.py:180: UserWarning: LogSoftmax final layer will be removed! Please adjust your loss function accordingly (e.g. CrossEntropyLoss)!\n",
            "  warnings.warn(\"LogSoftmax final layer will be removed! \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3       0.1500       26.6241  0.0391\n",
            "      4       0.1500       26.6241  0.0309\n",
            "      5       0.1500       26.6241  0.0335\n",
            "      6       0.1500       26.6241  0.0357\n",
            "      7       0.1500       26.6241  0.0349\n",
            "      8       0.1500       26.6241  0.0331\n",
            "      9       0.1500       26.6241  0.0625\n",
            "     10       0.1500       26.6241  0.0313\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'braindecode.classifier.EEGClassifier'>[initialized](\n",
              "  module_=============================================================================================================================================\n",
              "  Layer (type (var_name):depth-idx)        Input Shape               Output Shape              Param #                   Kernel Shape\n",
              "  ============================================================================================================================================\n",
              "  ShallowFBCSPNet (ShallowFBCSPNet)        [1, 3, 1024]              [1, 4]                    --                        --\n",
              "  ├─Ensure4d (ensuredims): 1-1             [1, 3, 1024]              [1, 3, 1024, 1]           --                        --\n",
              "  ├─Rearrange (dimshuffle): 1-2            [1, 3, 1024, 1]           [1, 1, 1024, 3]           --                        --\n",
              "  ├─CombinedConv (conv_time_spat): 1-3     [1, 1, 1024, 3]           [1, 40, 1000, 1]          5,840                     --\n",
              "  ├─BatchNorm2d (bnorm): 1-4               [1, 40, 1000, 1]          [1, 40, 1000, 1]          80                        --\n",
              "  ├─Expression (conv_nonlin_exp): 1-5      [1, 40, 1000, 1]          [1, 40, 1000, 1]          --                        --\n",
              "  ├─AvgPool2d (pool): 1-6                  [1, 40, 1000, 1]          [1, 40, 62, 1]            --                        [75, 1]\n",
              "  ├─Expression (pool_nonlin_exp): 1-7      [1, 40, 62, 1]            [1, 40, 62, 1]            --                        --\n",
              "  ├─Dropout (drop): 1-8                    [1, 40, 62, 1]            [1, 40, 62, 1]            --                        --\n",
              "  ├─Sequential (final_layer): 1-9          [1, 40, 62, 1]            [1, 4]                    --                        --\n",
              "  │    └─Conv2d (conv_classifier): 2-1     [1, 40, 62, 1]            [1, 4, 1, 1]              9,924                     [62, 1]\n",
              "  │    └─LogSoftmax (logsoftmax): 2-2      [1, 4, 1, 1]              [1, 4, 1, 1]              --                        --\n",
              "  │    └─Expression (squeeze): 2-3         [1, 4, 1, 1]              [1, 4]                    --                        --\n",
              "  ============================================================================================================================================\n",
              "  Total params: 15,844\n",
              "  Trainable params: 15,844\n",
              "  Non-trainable params: 0\n",
              "  Total mult-adds (M): 0.01\n",
              "  ============================================================================================================================================\n",
              "  Input size (MB): 0.01\n",
              "  Forward/backward pass size (MB): 0.32\n",
              "  Params size (MB): 0.04\n",
              "  Estimated Total Size (MB): 0.37\n",
              "  ============================================================================================================================================,\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(net.module_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNF3qoB5usMA",
        "outputId": "e5589d87-1eec-43b0-a053-2445d268e1fd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================================================================================================\n",
            "Layer (type (var_name):depth-idx)        Input Shape               Output Shape              Param #                   Kernel Shape\n",
            "============================================================================================================================================\n",
            "ShallowFBCSPNet (ShallowFBCSPNet)        [1, 3, 1024]              [1, 4]                    --                        --\n",
            "├─Ensure4d (ensuredims): 1-1             [1, 3, 1024]              [1, 3, 1024, 1]           --                        --\n",
            "├─Rearrange (dimshuffle): 1-2            [1, 3, 1024, 1]           [1, 1, 1024, 3]           --                        --\n",
            "├─CombinedConv (conv_time_spat): 1-3     [1, 1, 1024, 3]           [1, 40, 1000, 1]          5,840                     --\n",
            "├─BatchNorm2d (bnorm): 1-4               [1, 40, 1000, 1]          [1, 40, 1000, 1]          80                        --\n",
            "├─Expression (conv_nonlin_exp): 1-5      [1, 40, 1000, 1]          [1, 40, 1000, 1]          --                        --\n",
            "├─AvgPool2d (pool): 1-6                  [1, 40, 1000, 1]          [1, 40, 62, 1]            --                        [75, 1]\n",
            "├─Expression (pool_nonlin_exp): 1-7      [1, 40, 62, 1]            [1, 40, 62, 1]            --                        --\n",
            "├─Dropout (drop): 1-8                    [1, 40, 62, 1]            [1, 40, 62, 1]            --                        --\n",
            "├─Sequential (final_layer): 1-9          [1, 40, 62, 1]            [1, 4]                    --                        --\n",
            "│    └─Conv2d (conv_classifier): 2-1     [1, 40, 62, 1]            [1, 4, 1, 1]              9,924                     [62, 1]\n",
            "│    └─LogSoftmax (logsoftmax): 2-2      [1, 4, 1, 1]              [1, 4, 1, 1]              --                        --\n",
            "│    └─Expression (squeeze): 2-3         [1, 4, 1, 1]              [1, 4]                    --                        --\n",
            "============================================================================================================================================\n",
            "Total params: 15,844\n",
            "Trainable params: 15,844\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (M): 0.01\n",
            "============================================================================================================================================\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.32\n",
            "Params size (MB): 0.04\n",
            "Estimated Total Size (MB): 0.37\n",
            "============================================================================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'{net.module_.n_chans=}\\n{net.module_.n_times=}\\n{net.module_.n_outputs=}'\n",
        "      f'\\n{net.module_.input_window_seconds=}\\n{net.module_.sfreq=}\\n{net.module_.chs_info=}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PR7PlbKEuvxJ",
        "outputId": "e9da47a4-9381-493b-c94d-83aa1f4ee160"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "net.module_.n_chans=3\n",
            "net.module_.n_times=1024\n",
            "net.module_.n_outputs=4\n",
            "net.module_.input_window_seconds=4.0\n",
            "net.module_.sfreq=256.0\n",
            "net.module_.chs_info=[{'loc': array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]), 'unit_mul': 0 (FIFF_UNITM_NONE), 'range': 1.0, 'cal': 1.0, 'kind': 2 (FIFFV_EEG_CH), 'coil_type': 1 (FIFFV_COIL_EEG), 'unit': 107 (FIFF_UNIT_V), 'coord_frame': 4 (FIFFV_COORD_HEAD), 'ch_name': 'C3', 'scanno': 1, 'logno': 1}, {'loc': array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]), 'unit_mul': 0 (FIFF_UNITM_NONE), 'range': 1.0, 'cal': 1.0, 'kind': 2 (FIFFV_EEG_CH), 'coil_type': 1 (FIFFV_COIL_EEG), 'unit': 107 (FIFF_UNIT_V), 'coord_frame': 4 (FIFFV_COORD_HEAD), 'ch_name': 'C4', 'scanno': 2, 'logno': 2}, {'loc': array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]), 'unit_mul': 0 (FIFF_UNITM_NONE), 'range': 1.0, 'cal': 1.0, 'kind': 2 (FIFFV_EEG_CH), 'coil_type': 1 (FIFFV_COIL_EEG), 'unit': 107 (FIFF_UNIT_V), 'coord_frame': 4 (FIFFV_COORD_HEAD), 'ch_name': 'Cz', 'scanno': 3, 'logno': 3}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr>"
      ],
      "metadata": {
        "id": "p8g4XSxtu5-i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Test</h1>"
      ],
      "metadata": {
        "id": "d1olEMuVYI1s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.signal import butter, filtfilt, iirnotch, freqz\n",
        "import os"
      ],
      "metadata": {
        "id": "1gutAfIXvW59"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Band-pass filter\n",
        "def bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
        "    nyq = 0.5 * fs\n",
        "    low = lowcut / nyq\n",
        "    high = highcut / nyq\n",
        "    b, a = butter(order, [low, high], btype='band')\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y\n",
        "\n",
        "# Notch filter\n",
        "def notch_filter(data, cut_freq, fs, Q=30):\n",
        "    nyq = 0.5 * fs\n",
        "    freq = cut_freq / nyq\n",
        "    b, a = iirnotch(freq, Q)\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y\n",
        "\n",
        "def filter03050(Ipsignal):\n",
        "    sampling_rate = 250  # Hz\n",
        "    # fft_signal = np.fft.fft(Ipsignal)\n",
        "    # frequencies = np.fft.fftfreq(len(Ipsignal), 1/sampling_rate)\n",
        "    filtered_signal = bandpass_filter(Ipsignal, 1, 30, sampling_rate)          # band-pass filter 0-30 Hz\n",
        "    filtered_signal = notch_filter(filtered_signal, 50, sampling_rate)       # notch filter 50 Hz\n",
        "    return filtered_signal\n",
        "\n",
        "def unique_name(Datapath):\n",
        "    all_name = os.listdir(Datapath)\n",
        "    new = []\n",
        "    for un in all_name:\n",
        "        i = un.replace(\"_data_time_series.npy\",\"\").replace(\"_data_time_stamps.npy\",\"\").replace(\"_label_time_series.npy\",\"\").replace(\"_label_time_stamps.npy\",\"\")\n",
        "        new.append(i)\n",
        "        unique_name = list(set(new))\n",
        "    return unique_name\n",
        "\n",
        "def check_different_duration(label_time_stamps):\n",
        "    keep_time = []\n",
        "    start_time = 0\n",
        "    for current_time in list(label_time_stamps):\n",
        "        keep_time.append(current_time-start_time)\n",
        "        start_time = current_time\n",
        "    keep_time = keep_time[1:]\n",
        "    avgtime = sum(keep_time)/len(keep_time)\n",
        "    stat = True\n",
        "    for etime in keep_time:\n",
        "        if 6.8 <= etime <= 7.5:\n",
        "            stat = True\n",
        "        else:\n",
        "            stat = False\n",
        "            break\n",
        "    return stat,avgtime\n",
        "\n",
        "file_path = \"/content/mini_training\"\n",
        "unique_name = unique_name(file_path)\n",
        "\n",
        "data_dataset  = []\n",
        "label_dataset = []\n",
        "for name in unique_name:\n",
        "    print(name)\n",
        "    signals           = np.load(os.path.join(file_path,name+\"_data_time_series.npy\"))\n",
        "    times             = np.load(os.path.join(file_path,name+\"_data_time_stamps.npy\"))\n",
        "    label_time_series = np.load(os.path.join(file_path,name+\"_label_time_series.npy\"))\n",
        "    label_time_stamps = np.load(os.path.join(file_path,name+\"_label_time_stamps.npy\"))\n",
        "    signals = signals[:,:8]\n",
        "    stat,avgtime = check_different_duration(label_time_stamps)\n",
        "    if not(stat):\n",
        "        continue\n",
        "    # print(\"Avg time\",self.avgtime)\n",
        "    if filter!=None:\n",
        "        filtered_signal = []\n",
        "        Dim = signals.shape[1]\n",
        "        print(Dim)\n",
        "        for i in range(Dim):\n",
        "            # print(f\"{i} : {signals[:,i]}\")\n",
        "            filtered_signal.append(filter03050(signals[:,i]))\n",
        "        signals = np.array(filtered_signal).T\n",
        "    sample_point = int(round(avgtime))\n",
        "    datapoint = 250 * sample_point                   # 250 Hz * 7 s\n",
        "    for index in range(30):\n",
        "        start_point = index * datapoint\n",
        "        end_point = (index + 1) * datapoint\n",
        "        if end_point <= signals.shape[0]:  # Check to ensure slice is within the data range\n",
        "            data_dataset.append(signals[start_point:end_point])\n",
        "        else:\n",
        "            break\n",
        "    label_dataset.append(label_time_series)\n",
        "data_dataset = np.stack(data_dataset)\n",
        "\n",
        "label_dataset = np.concatenate(label_dataset)\n",
        "label_dataset = label_dataset.flatten().tolist()\n",
        "# print(data_dataset)\n",
        "# print(label_dataset)\n",
        "data_sliced_with_label = tuple(zip(data_dataset,label_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "956wCQHCu698",
        "outputId": "851e8dfa-2692-4ad2-bfda-ff1f251f68cc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "s1_d2_p002_002\n",
            "8\n",
            "s1_d2_p002_005\n",
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dataset.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9rjmBuGvb8N",
        "outputId": "43be2aa4-519c-45ec-ed49-ef67a5c2fd6d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60, 1750, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dataset = data_dataset.reshape(60, 8, 1750)\n",
        "data_dataset.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxMk09xdxOOd",
        "outputId": "08943336-bb15-4bf2-e239-63f76ed03ea5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60, 8, 1750)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr>"
      ],
      "metadata": {
        "id": "FgQ8VzdgxdCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Experiment</h1>"
      ],
      "metadata": {
        "id": "XvpNBf2bG7Gf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from braindecode.models.util import models_dict\n",
        "\n",
        "print(f'All the Braindecode models:\\n{list(models_dict.keys())}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrE2kfGdxVM0",
        "outputId": "1a3a844a-90ca-467a-ea98-ff901a236dc3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All the Braindecode models:\n",
            "['ATCNet', 'Deep4Net', 'DeepSleepNet', 'EEGConformer', 'EEGITNet', 'EEGInception', 'EEGInceptionERP', 'EEGInceptionMI', 'EEGNetv1', 'EEGNetv4', 'EEGResNet', 'HybridNet', 'ShallowFBCSPNet', 'SleepStagerBlanco2020', 'SleepStagerChambon2018', 'SleepStagerEldele2021', 'TCN', 'TIDNet', 'USleep']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from braindecode.models import ShallowFBCSPNet              # Import the model from braindecode * There are many model that available"
      ],
      "metadata": {
        "id": "yqORgJ8TxVKC"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ShallowFBCSPNet(\n",
        "    n_chans   = 8,\n",
        "    n_times   = 1750,\n",
        "    n_outputs = 3,\n",
        "    final_conv_length='auto',\n",
        ")\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkYAKrwmxVJV",
        "outputId": "798b918a-66ee-432d-85a2-1d5995ee0191"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================================================================================================\n",
            "Layer (type (var_name):depth-idx)        Input Shape               Output Shape              Param #                   Kernel Shape\n",
            "============================================================================================================================================\n",
            "ShallowFBCSPNet (ShallowFBCSPNet)        [1, 8, 1750]              [1, 3]                    --                        --\n",
            "├─Ensure4d (ensuredims): 1-1             [1, 8, 1750]              [1, 8, 1750, 1]           --                        --\n",
            "├─Rearrange (dimshuffle): 1-2            [1, 8, 1750, 1]           [1, 1, 1750, 8]           --                        --\n",
            "├─CombinedConv (conv_time_spat): 1-3     [1, 1, 1750, 8]           [1, 40, 1726, 1]          13,840                    --\n",
            "├─BatchNorm2d (bnorm): 1-4               [1, 40, 1726, 1]          [1, 40, 1726, 1]          80                        --\n",
            "├─Expression (conv_nonlin_exp): 1-5      [1, 40, 1726, 1]          [1, 40, 1726, 1]          --                        --\n",
            "├─AvgPool2d (pool): 1-6                  [1, 40, 1726, 1]          [1, 40, 111, 1]           --                        [75, 1]\n",
            "├─Expression (pool_nonlin_exp): 1-7      [1, 40, 111, 1]           [1, 40, 111, 1]           --                        --\n",
            "├─Dropout (drop): 1-8                    [1, 40, 111, 1]           [1, 40, 111, 1]           --                        --\n",
            "├─Sequential (final_layer): 1-9          [1, 40, 111, 1]           [1, 3]                    --                        --\n",
            "│    └─Conv2d (conv_classifier): 2-1     [1, 40, 111, 1]           [1, 3, 1, 1]              13,323                    [111, 1]\n",
            "│    └─LogSoftmax (logsoftmax): 2-2      [1, 3, 1, 1]              [1, 3, 1, 1]              --                        --\n",
            "│    └─Expression (squeeze): 2-3         [1, 3, 1, 1]              [1, 3]                    --                        --\n",
            "============================================================================================================================================\n",
            "Total params: 27,243\n",
            "Trainable params: 27,243\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (M): 0.01\n",
            "============================================================================================================================================\n",
            "Input size (MB): 0.06\n",
            "Forward/backward pass size (MB): 0.55\n",
            "Params size (MB): 0.05\n",
            "Estimated Total Size (MB): 0.66\n",
            "============================================================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/braindecode/models/base.py:180: UserWarning: LogSoftmax final layer will be removed! Please adjust your loss function accordingly (e.g. CrossEntropyLoss)!\n",
            "  warnings.warn(\"LogSoftmax final layer will be removed! \" +\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mne\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "_30uIpsaxVAi"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "info = mne.create_info(\n",
        "    ch_names = ['c1','c2','c3','c4','c5','c6','c7','c8'], sfreq=250., ch_types=\"eeg\"\n",
        ")\n",
        "# info = mne.create_info(ch_names=['C3', 'C4', 'Cz'], sfreq=256., ch_types='eeg')\n",
        "# X = np.random.randn(100, 3, 1024)  # 100 epochs, 3 channels, 4 seconds (@256Hz)\n",
        "epochs = mne.EpochsArray(data_dataset, info=info)\n",
        "# y = np.random.randint(0, 4, size=100)  # 4 classes\n",
        "# print(epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N55UDj1YxU99",
        "outputId": "65a3b5f6-dcb3-478a-bc19-fd0ab0676e00"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not setting metadata\n",
            "60 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ##########################################################\n",
        "# y = np.random.randint(0, 4, size=100)  # 4 classes\n",
        "# y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRYq64CnyhEu",
        "outputId": "f35fa612-abb1-4b7f-d8bb-9af19476e3d9"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 3, 3, 3, 1, 2, 0, 3, 1, 1, 0, 1, 3, 3, 3, 0, 0, 3, 3, 0, 0, 0,\n",
              "       1, 1, 2, 0, 3, 2, 1, 3, 0, 2, 2, 0, 1, 2, 2, 0, 1, 2, 3, 2, 0, 0,\n",
              "       1, 1, 1, 1, 0, 0, 0, 1, 3, 1, 2, 3, 1, 3, 0, 2, 3, 3, 0, 3, 2, 2,\n",
              "       0, 3, 2, 0, 3, 1, 1, 3, 2, 0, 3, 2, 0, 0, 2, 3, 2, 0, 0, 1, 2, 0,\n",
              "       3, 0, 1, 3, 2, 1, 1, 0, 2, 2, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_dataset = np.array(label_dataset)\n",
        "label_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6m1eY0dYyjvv",
        "outputId": "6434d1d5-8ac6-4a88-945c-04858af2df8c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([120, 110, 150, 150, 120, 110, 120, 110, 150, 150, 120, 110, 120,\n",
              "       150, 110, 150, 120, 110, 120, 110, 150, 150, 120, 110, 150, 120,\n",
              "       110, 150, 120, 110, 120, 110, 150, 150, 120, 110, 120, 110, 150,\n",
              "       150, 120, 110, 120, 150, 110, 150, 120, 110, 120, 110, 150, 150,\n",
              "       120, 110, 150, 120, 110, 150, 120, 110])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Map value\n",
        "mapping = {110: 0, 120: 1, 150: 2}\n",
        "\n",
        "mapped_label = np.vectorize(mapping.get)(label_dataset)\n",
        "print(mapped_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_kgCiguzA9N",
        "outputId": "f5414704-247a-47ef-c56b-c072b094dc4e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 2 2 1 0 1 0 2 2 1 0 1 2 0 2 1 0 1 0 2 2 1 0 2 1 0 2 1 0 1 0 2 2 1 0 1\n",
            " 0 2 2 1 0 1 2 0 2 1 0 1 0 2 2 1 0 2 1 0 2 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label = np.array(mapped_label)\n",
        "label\n",
        "################################################################"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jC5LWbzzHxl",
        "outputId": "bef8796a-69c3-4b9f-9839-01ce25668c2f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 2, 2, 1, 0, 1, 0, 2, 2, 1, 0, 1, 2, 0, 2, 1, 0, 1, 0, 2, 2,\n",
              "       1, 0, 2, 1, 0, 2, 1, 0, 1, 0, 2, 2, 1, 0, 1, 0, 2, 2, 1, 0, 1, 2,\n",
              "       0, 2, 1, 0, 1, 0, 2, 2, 1, 0, 2, 1, 0, 2, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from skorch.dataset import ValidSplit\n",
        "from braindecode import EEGClassifier\n",
        "\n",
        "net = EEGClassifier(\n",
        "    'ShallowFBCSPNet',\n",
        "    module__final_conv_length='auto',\n",
        "    train_split=ValidSplit(0.2),\n",
        "    # To train a neural network you need validation split, here, we use 20%.\n",
        ")\n",
        "# Train model\n",
        "net.fit(epochs, label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Up7f3J5OYokJ",
        "outputId": "ce2a4a91-305c-4ab5-f389-07c5bfb51c0a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch    valid_acc    valid_loss     dur\n",
            "-------  -----------  ------------  ------\n",
            "      1       \u001b[36m0.5833\u001b[0m       \u001b[32m38.9595\u001b[0m  0.0444\n",
            "      2       0.5833       38.9595  0.0354\n",
            "      3       0.5833       38.9595  0.0355\n",
            "      4       0.5833       38.9595  0.0364\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/braindecode/models/base.py:180: UserWarning: LogSoftmax final layer will be removed! Please adjust your loss function accordingly (e.g. CrossEntropyLoss)!\n",
            "  warnings.warn(\"LogSoftmax final layer will be removed! \" +\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      5       0.5833       38.9595  0.0393\n",
            "      6       0.5833       38.9595  0.0371\n",
            "      7       0.5833       38.9595  0.0517\n",
            "      8       0.5833       38.9595  0.0388\n",
            "      9       0.5833       38.9595  0.0373\n",
            "     10       0.5833       38.9595  0.0353\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'braindecode.classifier.EEGClassifier'>[initialized](\n",
              "  module_=============================================================================================================================================\n",
              "  Layer (type (var_name):depth-idx)        Input Shape               Output Shape              Param #                   Kernel Shape\n",
              "  ============================================================================================================================================\n",
              "  ShallowFBCSPNet (ShallowFBCSPNet)        [1, 8, 1750]              [1, 3]                    --                        --\n",
              "  ├─Ensure4d (ensuredims): 1-1             [1, 8, 1750]              [1, 8, 1750, 1]           --                        --\n",
              "  ├─Rearrange (dimshuffle): 1-2            [1, 8, 1750, 1]           [1, 1, 1750, 8]           --                        --\n",
              "  ├─CombinedConv (conv_time_spat): 1-3     [1, 1, 1750, 8]           [1, 40, 1726, 1]          13,840                    --\n",
              "  ├─BatchNorm2d (bnorm): 1-4               [1, 40, 1726, 1]          [1, 40, 1726, 1]          80                        --\n",
              "  ├─Expression (conv_nonlin_exp): 1-5      [1, 40, 1726, 1]          [1, 40, 1726, 1]          --                        --\n",
              "  ├─AvgPool2d (pool): 1-6                  [1, 40, 1726, 1]          [1, 40, 111, 1]           --                        [75, 1]\n",
              "  ├─Expression (pool_nonlin_exp): 1-7      [1, 40, 111, 1]           [1, 40, 111, 1]           --                        --\n",
              "  ├─Dropout (drop): 1-8                    [1, 40, 111, 1]           [1, 40, 111, 1]           --                        --\n",
              "  ├─Sequential (final_layer): 1-9          [1, 40, 111, 1]           [1, 3]                    --                        --\n",
              "  │    └─Conv2d (conv_classifier): 2-1     [1, 40, 111, 1]           [1, 3, 1, 1]              13,323                    [111, 1]\n",
              "  │    └─LogSoftmax (logsoftmax): 2-2      [1, 3, 1, 1]              [1, 3, 1, 1]              --                        --\n",
              "  │    └─Expression (squeeze): 2-3         [1, 3, 1, 1]              [1, 3]                    --                        --\n",
              "  ============================================================================================================================================\n",
              "  Total params: 27,243\n",
              "  Trainable params: 27,243\n",
              "  Non-trainable params: 0\n",
              "  Total mult-adds (M): 0.01\n",
              "  ============================================================================================================================================\n",
              "  Input size (MB): 0.06\n",
              "  Forward/backward pass size (MB): 0.55\n",
              "  Params size (MB): 0.05\n",
              "  Estimated Total Size (MB): 0.66\n",
              "  ============================================================================================================================================,\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'{net.module_.n_chans=}\\n{net.module_.n_times=}\\n{net.module_.n_outputs=}'\n",
        "      f'\\n{net.module_.input_window_seconds=}\\n{net.module_.sfreq=}\\n{net.module_.chs_info=}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f02SwKRk0bd4",
        "outputId": "d8c6807b-6139-4503-e6af-a31f1cbe2fc9"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "net.module_.n_chans=8\n",
            "net.module_.n_times=1750\n",
            "net.module_.n_outputs=3\n",
            "net.module_.input_window_seconds=7.0\n",
            "net.module_.sfreq=250.0\n",
            "net.module_.chs_info=[{'loc': array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]), 'unit_mul': 0 (FIFF_UNITM_NONE), 'range': 1.0, 'cal': 1.0, 'kind': 2 (FIFFV_EEG_CH), 'coil_type': 1 (FIFFV_COIL_EEG), 'unit': 107 (FIFF_UNIT_V), 'coord_frame': 4 (FIFFV_COORD_HEAD), 'ch_name': 'c1', 'scanno': 1, 'logno': 1}, {'loc': array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]), 'unit_mul': 0 (FIFF_UNITM_NONE), 'range': 1.0, 'cal': 1.0, 'kind': 2 (FIFFV_EEG_CH), 'coil_type': 1 (FIFFV_COIL_EEG), 'unit': 107 (FIFF_UNIT_V), 'coord_frame': 4 (FIFFV_COORD_HEAD), 'ch_name': 'c2', 'scanno': 2, 'logno': 2}, {'loc': array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]), 'unit_mul': 0 (FIFF_UNITM_NONE), 'range': 1.0, 'cal': 1.0, 'kind': 2 (FIFFV_EEG_CH), 'coil_type': 1 (FIFFV_COIL_EEG), 'unit': 107 (FIFF_UNIT_V), 'coord_frame': 4 (FIFFV_COORD_HEAD), 'ch_name': 'c3', 'scanno': 3, 'logno': 3}, {'loc': array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]), 'unit_mul': 0 (FIFF_UNITM_NONE), 'range': 1.0, 'cal': 1.0, 'kind': 2 (FIFFV_EEG_CH), 'coil_type': 1 (FIFFV_COIL_EEG), 'unit': 107 (FIFF_UNIT_V), 'coord_frame': 4 (FIFFV_COORD_HEAD), 'ch_name': 'c4', 'scanno': 4, 'logno': 4}, {'loc': array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]), 'unit_mul': 0 (FIFF_UNITM_NONE), 'range': 1.0, 'cal': 1.0, 'kind': 2 (FIFFV_EEG_CH), 'coil_type': 1 (FIFFV_COIL_EEG), 'unit': 107 (FIFF_UNIT_V), 'coord_frame': 4 (FIFFV_COORD_HEAD), 'ch_name': 'c5', 'scanno': 5, 'logno': 5}, {'loc': array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]), 'unit_mul': 0 (FIFF_UNITM_NONE), 'range': 1.0, 'cal': 1.0, 'kind': 2 (FIFFV_EEG_CH), 'coil_type': 1 (FIFFV_COIL_EEG), 'unit': 107 (FIFF_UNIT_V), 'coord_frame': 4 (FIFFV_COORD_HEAD), 'ch_name': 'c6', 'scanno': 6, 'logno': 6}, {'loc': array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]), 'unit_mul': 0 (FIFF_UNITM_NONE), 'range': 1.0, 'cal': 1.0, 'kind': 2 (FIFFV_EEG_CH), 'coil_type': 1 (FIFFV_COIL_EEG), 'unit': 107 (FIFF_UNIT_V), 'coord_frame': 4 (FIFFV_COORD_HEAD), 'ch_name': 'c7', 'scanno': 7, 'logno': 7}, {'loc': array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]), 'unit_mul': 0 (FIFF_UNITM_NONE), 'range': 1.0, 'cal': 1.0, 'kind': 2 (FIFFV_EEG_CH), 'coil_type': 1 (FIFFV_COIL_EEG), 'unit': 107 (FIFF_UNIT_V), 'coord_frame': 4 (FIFFV_COORD_HEAD), 'ch_name': 'c8', 'scanno': 8, 'logno': 8}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Predict</h1>"
      ],
      "metadata": {
        "id": "Q7zBxPfun3x1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip /content/Test_data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyBmSZKin9UU",
        "outputId": "62505705-4576-400f-ad0f-3a50d1817288"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/Test_data.zip\n",
            "   creating: Test_data/\n",
            "  inflating: Test_data/s1_d2_p003_001_data_time_series.npy  \n",
            "  inflating: Test_data/s1_d2_p003_001_data_time_stamps.npy  \n",
            "  inflating: Test_data/s1_d2_p003_001_label_time_series.npy  \n",
            "  inflating: Test_data/s1_d2_p003_001_label_time_stamps.npy  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = np.load(\"/content/Test_data/s1_d2_p003_001_data_time_series.npy\")"
      ],
      "metadata": {
        "id": "pAM88lvbtIt3"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dataset  = []\n",
        "label_dataset = []\n",
        "file_path = \"/content/Test_data\"\n",
        "unique_name = [\"s1_d2_p003_001\"]\n",
        "for name in unique_name:\n",
        "    print(name)\n",
        "    signals           = np.load(os.path.join(file_path,name+\"_data_time_series.npy\"))\n",
        "    times             = np.load(os.path.join(file_path,name+\"_data_time_stamps.npy\"))\n",
        "    label_time_series = np.load(os.path.join(file_path,name+\"_label_time_series.npy\"))\n",
        "    label_time_stamps = np.load(os.path.join(file_path,name+\"_label_time_stamps.npy\"))\n",
        "    signals = signals[:,:8]\n",
        "    stat,avgtime = check_different_duration(label_time_stamps)\n",
        "    if not(stat):\n",
        "        continue\n",
        "    # print(\"Avg time\",self.avgtime)\n",
        "    if filter!=None:\n",
        "        filtered_signal = []\n",
        "        Dim = signals.shape[1]\n",
        "        print(Dim)\n",
        "        for i in range(Dim):\n",
        "            # print(f\"{i} : {signals[:,i]}\")\n",
        "            filtered_signal.append(filter03050(signals[:,i]))\n",
        "        signals = np.array(filtered_signal).T\n",
        "    sample_point = int(round(avgtime))\n",
        "    datapoint = 250 * sample_point                   # 250 Hz * 7 s\n",
        "    for index in range(30):\n",
        "        start_point = index * datapoint\n",
        "        end_point = (index + 1) * datapoint\n",
        "        if end_point <= signals.shape[0]:  # Check to ensure slice is within the data range\n",
        "            data_dataset.append(signals[start_point:end_point])\n",
        "        else:\n",
        "            break\n",
        "    label_dataset.append(label_time_series)\n",
        "\n",
        "data_dataset = np.stack(data_dataset)\n",
        "\n",
        "label_dataset = np.concatenate(label_dataset)\n",
        "label_dataset = label_dataset.flatten().tolist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFjbZSoDt35e",
        "outputId": "a7df696f-3e0f-40a0-c46a-3eebf0049e41"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "s1_d2_p003_001\n",
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dataset = data_dataset.reshape(30,8,1750)\n",
        "data_dataset.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpzIthnzvCOL",
        "outputId": "97658bb6-2bec-4cb1-c33a-5cb4c4b84787"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30, 8, 1750)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_epochs = mne.EpochsArray(data_dataset,info=info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avP7BQI3wejA",
        "outputId": "92b5ca7a-d295-4fd9-9e44-a0f6596accfd"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not setting metadata\n",
            "30 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get predictions from the trained model\n",
        "predictions = net.predict(test_epochs)\n",
        "probabilities = net.predict_proba(test_epochs)"
      ],
      "metadata": {
        "id": "w7w-teEywm9Q"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Predictions:\", predictions)\n",
        "print(\"Probabilities:\", probabilities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-n3e0tvUwor9",
        "outputId": "d01a7a1d-d10f-43f3-a166-a082a641186a"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "Probabilities: [[2.1184293e-23 0.0000000e+00 1.0000000e+00]\n",
            " [1.4548094e-21 0.0000000e+00 1.0000000e+00]\n",
            " [7.5185719e-22 0.0000000e+00 1.0000000e+00]\n",
            " [4.6278721e-22 0.0000000e+00 1.0000000e+00]\n",
            " [4.8391015e-22 0.0000000e+00 1.0000000e+00]\n",
            " [2.9542154e-22 0.0000000e+00 1.0000000e+00]\n",
            " [2.7656325e-22 0.0000000e+00 1.0000000e+00]\n",
            " [2.1029472e-22 0.0000000e+00 1.0000000e+00]\n",
            " [9.8257573e-23 0.0000000e+00 1.0000000e+00]\n",
            " [7.2325262e-22 0.0000000e+00 1.0000000e+00]\n",
            " [1.1301319e-21 0.0000000e+00 1.0000000e+00]\n",
            " [1.0181615e-21 0.0000000e+00 1.0000000e+00]\n",
            " [5.9576482e-22 0.0000000e+00 1.0000000e+00]\n",
            " [2.3422681e-23 0.0000000e+00 1.0000000e+00]\n",
            " [3.9782401e-24 0.0000000e+00 1.0000000e+00]\n",
            " [6.1452643e-22 0.0000000e+00 1.0000000e+00]\n",
            " [2.5049063e-22 0.0000000e+00 1.0000000e+00]\n",
            " [1.5195583e-21 0.0000000e+00 1.0000000e+00]\n",
            " [1.1567777e-21 0.0000000e+00 1.0000000e+00]\n",
            " [3.8662596e-22 0.0000000e+00 1.0000000e+00]\n",
            " [1.1006006e-22 0.0000000e+00 1.0000000e+00]\n",
            " [3.7755888e-22 0.0000000e+00 1.0000000e+00]\n",
            " [9.7338336e-23 0.0000000e+00 1.0000000e+00]\n",
            " [2.1816521e-23 0.0000000e+00 1.0000000e+00]\n",
            " [9.6171702e-22 0.0000000e+00 1.0000000e+00]\n",
            " [5.2430659e-22 0.0000000e+00 1.0000000e+00]\n",
            " [3.0936670e-21 0.0000000e+00 1.0000000e+00]\n",
            " [4.8598416e-21 0.0000000e+00 1.0000000e+00]\n",
            " [9.0419767e-22 0.0000000e+00 1.0000000e+00]\n",
            " [1.2552051e-22 0.0000000e+00 1.0000000e+00]]\n"
          ]
        }
      ]
    }
  ]
}